{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/meenub255/NXP_SEM_DEFECT/blob/main/Synthethic_Generation_for_Dataset_of_SEM_images.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torchvision.transforms as T\n",
        "import matplotlib.pyplot as plt\n",
        "# ==========================================\n",
        "# 1. Configuration\n",
        "# ==========================================\n",
        "# Input folder containing class subfolders (e.g., /content/dataset/opens, /content/dataset/bridges)\n",
        "INPUT_DATASET_PATH = \"/content/drive/MyDrive/sem\"\n",
        "# Output folder where augmented images will be saved\n",
        "OUTPUT_DATASET_PATH = \"/content/drive/MyDrive/Hackathon_Images/Augmented_Dataset_10x\"\n",
        "# How many augmented versions to create per original image\n",
        "# 50 images * 10 = 500 images (Meets Hackathon Req)\n",
        "AUGMENTATION_FACTOR = 10\n",
        "# ==========================================\n",
        "# 2. Augmentation Strategy\n",
        "# ==========================================\n",
        "def get_augmentation_pipeline(img_size=224):\n",
        "    \"\"\"\n",
        "    Defines the random transformations to apply.\n",
        "    \"\"\"\n",
        "    return T.Compose([\n",
        "        T.Resize((img_size + 32, img_size + 32)),  # Resize slightly larger\n",
        "        T.RandomCrop(img_size),                     # Random crop\n",
        "        T.RandomHorizontalFlip(p=0.5),              # 50% chance to flip LR\n",
        "        T.RandomVerticalFlip(p=0.5),                # 50% chance to flip UD (Valid for wafer dies)\n",
        "        T.RandomRotation(degrees=45),               # Rotate\n",
        "        T.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.2), # Lighting noise\n",
        "        T.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)), # Zoom/Shift\n",
        "        # Note: We do NOT convert to Tensor here because we want to save as Image\n",
        "    ])\n",
        "# ==========================================\n",
        "# 3. Execution Engine\n",
        "# ==========================================\n",
        "def run_augmentation():\n",
        "    # 0. Setup Paths\n",
        "    input_path = Path(INPUT_DATASET_PATH)\n",
        "    output_path = Path(OUTPUT_DATASET_PATH)\n",
        "\n",
        "    if not input_path.exists():\n",
        "        print(f\"Error: Input path '{input_path}' does not exist.\")\n",
        "        print(\"Please mount Google Drive and check the path.\")\n",
        "        return\n",
        "    # Create output directory\n",
        "    if output_path.exists():\n",
        "        user_input = input(f\"Output path '{output_path}' exists. Overwrite? (y/n): \")\n",
        "        if user_input.lower() == 'y':\n",
        "            shutil.rmtree(output_path)\n",
        "        else:\n",
        "            print(\"Aborted.\")\n",
        "            return\n",
        "    output_path.mkdir(parents=True, exist_ok=True)\n",
        "    # 1. Pipeline\n",
        "    augmenter = get_augmentation_pipeline(img_size=224)\n",
        "\n",
        "    # 2. Iterate Classes\n",
        "    classes = [d for d in input_path.iterdir() if d.is_dir()]\n",
        "    print(f\"Found {len(classes)} classes: {[c.name for c in classes]}\")\n",
        "    for class_dir in tqdm(classes, desc=\"Processing Classes\"):\n",
        "        class_name = class_dir.name\n",
        "\n",
        "        # Create corresponding output class folder\n",
        "        target_dir = output_path / class_name\n",
        "        target_dir.mkdir(exist_ok=True)\n",
        "\n",
        "        images = list(class_dir.glob(\"*.[jJpP][pPnN][gG]\")) # Match jpg, png, jpeg\n",
        "        print(f\"  Class '{class_name}': Found {len(images)} images.\")\n",
        "\n",
        "        for img_file in images:\n",
        "            try:\n",
        "                # Open Image\n",
        "                with Image.open(img_file).convert(\"RGB\") as img:\n",
        "\n",
        "                    # Save Original (Clean copy)\n",
        "                    save_name = f\"{img_file.stem}_orig.jpg\"\n",
        "                    img.resize((224, 224)).save(target_dir / save_name, quality=95)\n",
        "\n",
        "                    # Generate Augmented Versions\n",
        "                    for i in range(AUGMENTATION_FACTOR):\n",
        "                        aug_img = augmenter(img)\n",
        "\n",
        "                        # Save Augmented\n",
        "                        save_name = f\"{img_file.stem}_aug_{i}.jpg\"\n",
        "                        aug_img.save(target_dir / save_name, quality=90)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"    Error processing {img_file.name}: {e}\")\n",
        "    print(f\"\\nSuccess! Augmented dataset saved to: {output_path}\")\n",
        "    print(f\"Start Count: ~{sum([len(list(c.glob('*'))) for c in classes])}\")\n",
        "    print(f\"Final Count: ~{sum([len(list(c.glob('*'))) for c in output_path.iterdir()])}\")\n",
        "# ==========================================\n",
        "# 4. Run\n",
        "# ==========================================\n",
        "if __name__ == \"__main__\":\n",
        "    # Ensure Torchvision is installed\n",
        "    try:\n",
        "        import torchvision\n",
        "        run_augmentation()\n",
        "    except ImportError:\n",
        "        print(\"Installing dependencies...\")\n",
        "        os.system(\"pip install torchvision tqdm\")\n",
        "        run_augmentation()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICv35WXb6z8H",
        "outputId": "3a078dee-289b-4fa9-a654-a0c293fc169d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output path '/content/drive/MyDrive/Hackathon_Images/Augmented_Dataset_10x' exists. Overwrite? (y/n): y\n",
            "Found 5 classes: ['opens', 'cracks', 'bridge', 'vias', 'CMP']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Classes:   0%|          | 0/5 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Class 'opens': Found 49 images.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Classes:  20%|██        | 1/5 [00:42<02:48, 42.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Class 'cracks': Found 21 images.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Classes:  40%|████      | 2/5 [01:03<01:30, 30.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Class 'bridge': Found 22 images.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Classes:  60%|██████    | 3/5 [01:24<00:51, 25.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Class 'vias': Found 2 images.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Classes:  80%|████████  | 4/5 [01:25<00:16, 16.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Class 'CMP': Found 70 images.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Classes: 100%|██████████| 5/5 [02:22<00:00, 28.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Success! Augmented dataset saved to: /content/drive/MyDrive/Hackathon_Images/Augmented_Dataset_10x\n",
            "Start Count: ~167\n",
            "Final Count: ~1804\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "40m5KP4u_2yY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77648806",
        "outputId": "61b50e28-e33d-4647-bae2-c8750c3661a5"
      },
      "source": [
        "from pathlib import Path\n",
        "\n",
        "def count_augmented_images_per_class(output_path_str):\n",
        "    output_path = Path(output_path_str)\n",
        "    if not output_path.exists():\n",
        "        print(f\"Error: Output path '{output_path}' does not exist.\")\n",
        "        return\n",
        "\n",
        "    class_counts = {}\n",
        "    classes = [d for d in output_path.iterdir() if d.is_dir()]\n",
        "    print(f\"Counting images in {len(classes)} classes:\")\n",
        "\n",
        "    for class_dir in classes:\n",
        "        class_name = class_dir.name\n",
        "        # Count all image files (jpg, png, jpeg) in the class directory\n",
        "        images = list(class_dir.glob(\"*.[jJpP][pPnN][gG]\"))\n",
        "        class_counts[class_name] = len(images)\n",
        "\n",
        "    print(\"\\n--- Augmented Image Counts per Class ---\")\n",
        "    for class_name, count in class_counts.items():\n",
        "        print(f\"Class '{class_name}': {count} images\")\n",
        "    print(\"----------------------------------------\")\n",
        "\n",
        "# Assuming OUTPUT_DATASET_PATH is defined in the previous cells\n",
        "if 'OUTPUT_DATASET_PATH' in globals():\n",
        "    count_augmented_images_per_class(OUTPUT_DATASET_PATH)\n",
        "else:\n",
        "    print(\"OUTPUT_DATASET_PATH not defined. Please run the augmentation cell first.\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counting images in 5 classes:\n",
            "\n",
            "--- Augmented Image Counts per Class ---\n",
            "Class 'opens': 539 images\n",
            "Class 'cracks': 231 images\n",
            "Class 'bridge': 242 images\n",
            "Class 'vias': 22 images\n",
            "Class 'CMP': 770 images\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Push Code to GitHub from Colab\n",
        "# Run this cell to push your work to https://github.com/Shashwath-K/nxp_semi_project.git\n",
        "\n",
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "# 1. Configuration\n",
        "USER_NAME = \"meenub255\"\n",
        "USER_EMAIL = \"meenub255@gmail.com\" # <--- REPLACE THIS\n",
        "REPO_NAME = \"NXP_SEM_DEFECT\"\n",
        "REPO_URL = f\"https://github.com/{USER_NAME}/{REPO_NAME}.git\"\n",
        "\n",
        "# 2. Files to Push (List of files you want to save)\n",
        "# Assuming you have saved the previous scripts as .py files in Colab\n",
        "FILES_TO_PUSH = [\n",
        "    \"data_augmentation.py\",        # From previous steps\n",
        "    \"colab_training_pipeline.py\",  # From previous steps\n",
        "    \"best_student_model.pth\"       # If you want to push the model (Warning: Large file!)\n",
        "]\n",
        "\n",
        "# 3. Authentication (Securely ask for Token)\n",
        "print(\"Please enter your GitHub Personal Access Token (PAT):\")\n",
        "print(\"(Settings -> Developer settings -> Personal access tokens -> Tokens (classic))\")\n",
        "token = getpass()\n",
        "\n",
        "# 4. Git Operations\n",
        "def push_to_github():\n",
        "    # Configure Git\n",
        "    !git config --global user.email \"{USER_EMAIL}\"\n",
        "    !git config --global user.name \"{USER_NAME}\"\n",
        "\n",
        "    # Clone (into a temp folder to avoid messy paths)\n",
        "    if os.path.exists(REPO_NAME):\n",
        "        !rm -rf {REPO_NAME}\n",
        "\n",
        "    print(f\"Cloning {REPO_NAME}...\")\n",
        "    !git clone https://{token}@github.com/{USER_NAME}/{REPO_NAME}.git\n",
        "\n",
        "    # Move files into Repo\n",
        "    print(\"Moving files to repo...\")\n",
        "    import shutil\n",
        "    for file in FILES_TO_PUSH:\n",
        "        if os.path.exists(file):\n",
        "            shutil.copy(file, f\"{REPO_NAME}/{file}\")\n",
        "            print(f\"  Added: {file}\")\n",
        "        else:\n",
        "            print(f\"  Warning: {file} not found in Colab root.\")\n",
        "\n",
        "    # Commit & Push\n",
        "    os.chdir(REPO_NAME)\n",
        "    !git add .\n",
        "    !git commit -m \"Add Hackathon training pipeline and data augmentation scripts\"\n",
        "    !git push origin main\n",
        "    print(\"\\nSuccess! Code pushed to GitHub.\")\n",
        "    os.chdir(\".\")\n",
        "\n",
        "push_to_github()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jx1KfjzSCmeW",
        "outputId": "f151ac03-3273-4d65-faf9-fbb8d0b8af9f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please enter your GitHub Personal Access Token (PAT):\n",
            "(Settings -> Developer settings -> Personal access tokens -> Tokens (classic))\n",
            "··········\n",
            "Cloning NXP_SEM_DEFECT...\n",
            "Cloning into 'NXP_SEM_DEFECT'...\n",
            "warning: You appear to have cloned an empty repository.\n",
            "Moving files to repo...\n",
            "  Warning: data_augmentation.py not found in Colab root.\n",
            "  Warning: colab_training_pipeline.py not found in Colab root.\n",
            "  Warning: best_student_model.pth not found in Colab root.\n",
            "On branch main\n",
            "\n",
            "Initial commit\n",
            "\n",
            "nothing to commit (create/copy files and use \"git add\" to track)\n",
            "error: src refspec main does not match any\n",
            "\u001b[31merror: failed to push some refs to 'https://github.com/meenub255/NXP_SEM_DEFECT.git'\n",
            "\u001b[m\n",
            "Success! Code pushed to GitHub.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "mount_file_id": "1AIk8-Ut-6O9VCg1i4LNQ_W1ZxKYtftDn",
      "authorship_tag": "ABX9TyN541DUGQ19P/rzLzc3HOQU",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}